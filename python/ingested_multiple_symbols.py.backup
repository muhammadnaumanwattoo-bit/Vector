import os
import asyncio
from datetime import datetime, timedelta
from typing import Any, Dict, List, Tuple
from dotenv import load_dotenv
from supabase import create_client, Client
from providers.alpha_vantage import AlphaVantageProvider
from providers.types import CandleDaily

import logging
logging.basicConfig(
    level=logging.INFO,  # üëà allow INFO and above
    format="%(asctime)s [%(levelname)s] %(name)s: %(message)s",
    handlers=[logging.StreamHandler()]  # üëà ensure logs go to terminal
)
logger = logging.getLogger(__name__)




def iso_date(dt: datetime) -> str:
	return dt.strftime("%Y-%m-%d")


def resolve_alpha_vantage_symbol(input_symbol: str) -> Tuple[str, str]:
	"""
	Return (api_symbol, note). For unsupported tickers, map to closest ETF proxy.
	- Crypto pairs (e.g., BTC-USD, ETH-USD) are passed through
	- Indices/futures map to ETFs where possible
	"""
	s = input_symbol.strip()
	upper = s.upper()
	# Crypto pairs supported by our provider
	if "-" in upper and upper.endswith("-USD"):
		return upper, "crypto"
	# Known proxies for Alpha Vantage support
	proxy_map = {
		"^GSPC": "SPY",   # S&P 500 ‚Üí SPY ETF
		"^IXIC": "QQQ",   # NASDAQ Composite ‚Üí QQQ ETF
		"^TNX": "IEF",    # 10Y yield ‚Üí 7-10Y Treasury ETF proxy
		"GC=F": "GLD",    # Gold futures ‚Üí GLD ETF
	}
	if upper in proxy_map:
		return proxy_map[upper], f"proxy_for:{upper}"
	# Skip other Yahoo-style indices/futures if any
	if upper.startswith("^") or ("=F" in upper):
		return "", "skip_unsupported"
	# Default passthrough for equities like AAPL, TSLA, IBM
	return upper, "equity"


def aggregate_intraday_to_daily(intraday: List[Dict[str, Any]]) -> Dict[str, Dict[str, Any]]:
	"""
	Aggregate a list of dicts with keys ts, open, high, low, close, volume into
	daily bars keyed by date YYYY-MM-DD.
	"""
	by_date: Dict[str, Dict[str, Any]] = {}
	for c in intraday:
		# ts is e.g. '2025-09-22 13:00:00'
		date_key = c["ts"][0:10]
		bar = by_date.get(date_key)
		if not bar:
			by_date[date_key] = {
				"open": c["open"],
				"high": c["high"],
				"low": c["low"],
				"close": c["close"],
				"volume": c.get("volume") or 0,
				"first_ts": c["ts"],
				"last_ts": c["ts"],
			}
		else:
			bar["high"] = max(bar["high"], c["high"])
			bar["low"] = min(bar["low"], c["low"])
			# Open stays from earliest ts; Close from latest ts
			if c["ts"] < bar["first_ts"]:
				bar["first_ts"] = c["ts"]
				bar["open"] = c["open"]
			if c["ts"] > bar["last_ts"]:
				bar["last_ts"] = c["ts"]
				bar["close"] = c["close"]
			bar["volume"] = (bar.get("volume") or 0) + (c.get("volume") or 0)
	return by_date


async def ingest_alpha_vantage(display_symbol: str, api_symbol: str | None = None, run_type: str = "daily") -> Dict[str, Any]:
	load_dotenv()
	url = os.environ.get("SUPABASE_URL")
	key = os.environ.get("SUPABASE_SERVICE_ROLE_KEY")
	if not url or not key:
		raise RuntimeError("SUPABASE_URL and SUPABASE_SERVICE_ROLE_KEY are required")

	client: Client = create_client(url, key)
	provider = AlphaVantageProvider()

	instrument_symbol = display_symbol
	fetch_symbol = api_symbol or display_symbol

	# First, let's find or create the instrument record using the DISPLAY symbol
	instruments_resp = client.table("instruments").select("*").eq("symbol", instrument_symbol).limit(1).execute()
	
	instrument_id = None
	if instruments_resp.data and len(instruments_resp.data) > 0:
		instrument_id = instruments_resp.data[0]["id"]
		logger.info(f"‚úÖ Found existing instrument_id: {instrument_id} for symbol: {instrument_symbol}")
	else:
		# Create new instrument record with proper fields
		logger.info(f"üìù Creating new instrument record for symbol: {instrument_symbol}")
		inst_type = (
			"crypto" if ("-" in instrument_symbol and instrument_symbol.upper().endswith("-USD"))
			else "index" if instrument_symbol.startswith("^")
			else "future" if ("=F" in instrument_symbol)
			else "equity"
		)
		new_instrument = client.table("instruments").insert({
			"symbol": instrument_symbol,
			"name": instrument_symbol,
			"type": inst_type,
			"provider": "Alpha Vantage",
			"currency": "USD"
		}).execute()
		
		if new_instrument.data:
			instrument_id = new_instrument.data[0]["id"]
			logger.info(f"‚úÖ Created instrument_id: {instrument_id} for symbol: {instrument_symbol}")
		else:
			raise RuntimeError(f"Failed to create instrument record for {instrument_symbol}")

	# Check existing data to determine date range
	# Use a small overlap (default 1 day) to avoid missing late updates, rely on upsert to dedupe
	overlap_days = int(os.environ.get("FETCH_OVERLAP_DAYS", "1"))
	since: str | None = None
	
	resp = client.table("ohlcv_data").select("date").eq("instrument_id", instrument_id).order("date", desc=True).limit(1).execute()
	if resp.data and len(resp.data) > 0:
		last_date = datetime.fromisoformat(str(resp.data[0]["date"]))
		since_dt = last_date - timedelta(days=overlap_days)
		since = iso_date(since_dt)
		logger.info(f"üìÖ Last data date: {last_date.strftime('%Y-%m-%d')}, fetching from: {since}")
	else:
		# Set default start date to January 1, 2022
		since = "2022-01-01"

		logger.warning(f"üìÖ No existing data found, fetching from default start date: {since}")

	today = iso_date(datetime.utcnow())

	

	# Fetch using the API symbol (could be a proxy like SPY for ^GSPC)
	candles: List[CandleDaily] = await provider.fetch_daily(fetch_symbol, since, today)
	upserts = 0

	logger.info(f"üìä Fetched {len(candles)} candles from Alpha Vantage for {fetch_symbol} (storing under {instrument_symbol})")

	# Process candles in batches to avoid issues
	batch_size = int(os.environ.get("ALPHA_VANTAGE_BATCH_SIZE", "50"))
	
	for i in range(0, len(candles), batch_size):
		batch = candles[i:i + batch_size]
		rows = []
		logger.info(f"üì¶ Processing batch {i//batch_size + 1}/{(len(candles) + batch_size - 1)//batch_size}")
		
		for c in batch:
			if not c.date:
				continue
			rows.append(
				{
				"instrument_id": instrument_id,
				"instrument_symbol": instrument_symbol,
				"date": c.date,
				"open": c.open,
				"high": c.high,
				"low": c.low,
				"close": c.close,
				"volume": c.volume or 0,
			}

			)
		if not rows:
			continue
					

			
		try:
			# Atomic upsert avoids duplicates on (instrument_id, date)
			client.table("ohlcv_data").upsert(rows, on_conflict="instrument_id,date").execute()
			upserts += len(rows)
			logger.info(f"Upserted {len(rows)} candles for {instrument_symbol}")
		except Exception as e:
			logger.warning(f"Error upserting batch for {instrument_symbol}: {e}")

			continue

	logger.info(f"‚úÖ Successfully processed {upserts} records under {instrument_symbol}")

	return {"ok": True, "upserts": upserts, "mode": "daily"}


if __name__ == "__main__":
	load_dotenv()

	# Accept a comma-separated list of symbols via SYMBOLS, otherwise fallback to single SYMBOL
	symbols_env = os.environ.get("SYMBOLS", "")
	if symbols_env.strip():
		symbols = [s.strip() for s in symbols_env.split(",") if s.strip()]
	else:
		single_symbol = os.environ.get("SYMBOL", "").strip()
		symbols = [single_symbol] if single_symbol else []

	if not symbols:
		logger.info("‚ö†Ô∏è No symbols provided. Set SYMBOLS='AAPL,TSLA' or SYMBOL='AAPL'.")
		exit(1)

	logger.info(f"üöÄ Starting ingestion for symbols: {symbols}")

	async def run_all():
		results: Dict[str, Any] = {}
		for idx, orig_sym in enumerate(symbols, start=1):
			api_sym, note = resolve_alpha_vantage_symbol(orig_sym)
			if note == "skip_unsupported" or not api_sym:
				logger.info(f"‚è≠Ô∏è Skipping unsupported for Alpha Vantage: {orig_sym}")
				continue
			if api_sym != orig_sym:
				logger.info(f"üîÅ Mapping {orig_sym} ‚Üí {api_sym} ({note})")

			logger.info(f"‚û°Ô∏è [{idx}/{len(symbols)}] Processing {orig_sym} (fetch {api_sym})")
			try:
				res = await ingest_alpha_vantage(display_symbol=orig_sym, api_symbol=api_sym)
				results[orig_sym] = {"api_symbol": api_sym, **res}
				# Respect Alpha Vantage free tier: up to 5 requests/min ‚Üí ~12-15s gap
				sleep_time = int(os.environ.get("ALPHA_VANTAGE_SLEEP_SECONDS", "2"))
				await asyncio.sleep(sleep_time)
			except Exception as e:
				logger.warning(f"‚ùå Failed {orig_sym} (via {api_sym}): {e}")
				results[orig_sym] = {"ok": False, "error": str(e), "api_symbol": api_sym}
		return results

	final_results = asyncio.run(run_all())
	logger.info(f"üéâ Completed: {final_results}")
